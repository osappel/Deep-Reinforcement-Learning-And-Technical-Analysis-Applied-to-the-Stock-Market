{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex2ord116AbP"
   },
   "source": [
    "* [1. Aprendizado de todos os Modelos X Todos os tipos de recompensa](#0)\n",
    "* [2. Predição de todos os Modelos X Todos os tipos de recompensa](#1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n",
    "import os\n",
    "import gym\n",
    "from gym.utils import seeding\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.vec_env import VecVideoRecorder, DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy\n",
    "from stable_baselines3.common import logger\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "from IPython import display as ipythondisplay\n",
    "from copy import copy\n",
    "import ta\n",
    "from ta.trend import PSARIndicator, SMAIndicator, MACD, CCIIndicator, ADXIndicator\n",
    "from ta.volume import MFIIndicator\n",
    "from ta.momentum import RSIIndicator, StochRSIIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ILY0AkFfzPJ"
   },
   "outputs": [],
   "source": [
    "class SimpleCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(SimpleCallback, self).__init__(verbose)\n",
    "        self._called = False\n",
    "    \n",
    "    def _on_step(self):\n",
    "        print(\"\\rNum timesteps: {}\".format(self.num_timesteps), end = \"\")\n",
    "\n",
    "        return True # returns True, training continues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df, start, end):\n",
    "    \"\"\"\n",
    "    split the dataset into training or testing using date\n",
    "    :param data: (df) pandas dataframe, start, end\n",
    "    :return: (df) pandas dataframe\n",
    "    \"\"\"\n",
    "    data = df[(df.date >= start) & (df.date < end)]\n",
    "    data = data.sort_values([\"date\"], ignore_index=True)\n",
    "    data.index = data.date.factorize()[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LearnModel(Model, \n",
    "               df ,\n",
    "               initial_account = 1e6 ,\n",
    "               reward_low = -1 ,  \n",
    "               reward_high = 0.1 , \n",
    "               reward_tipo = 'spot', # 'mfi' ou 'spot' ou 'rsi' \n",
    "               total_timesteps = 10000, \n",
    "               verbose = False): \n",
    "    \n",
    "    def Models(Model):\n",
    "        MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n",
    "        return MODELS[Model]\n",
    "    \n",
    "    def Params(Model,env):\n",
    "        PARAMS = {\"a2c\":{\n",
    "                        'env': env,\n",
    "                        \"policy\":\"MlpPolicy\",    \n",
    "                        \"n_steps\": 5, \n",
    "                        \"ent_coef\": 0.005, \n",
    "                        \"learning_rate\": 0.0002,\n",
    "                        \"device\": 'cuda',\n",
    "                        \"verbose\": 0,\n",
    "                        '_init_setup_model': True,\n",
    "                        'seed': 1024\n",
    "                        },\n",
    "                  \"ddpg\": {\n",
    "                        'env': env,\n",
    "                        \"policy\":\"MlpPolicy\",    \n",
    "                        \"batch_size\": 64, \n",
    "                        \"buffer_size\": 500000, \n",
    "                        \"learning_rate\": 0.0001,\n",
    "                        \"device\": 'cuda',\n",
    "                        \"verbose\": 0,\n",
    "                        '_init_setup_model': True,\n",
    "                        'seed': 1024    \n",
    "                        }, \n",
    "                  \"td3\": {\n",
    "                        'env': env,\n",
    "                        \"policy\":\"MlpPolicy\",    \n",
    "                        \"batch_size\": 128,\n",
    "                        \"buffer_size\": 1000000, \n",
    "                        \"learning_rate\": 0.0003,\n",
    "                        \"device\": 'cuda',\n",
    "                        \"verbose\": 0,\n",
    "                        '_init_setup_model': True,\n",
    "                        'seed': 1024             \n",
    "                        }, \n",
    "                  \"sac\": {\n",
    "                        'env': env,\n",
    "                        \"policy\":\"MlpPolicy\",    \n",
    "                        \"batch_size\": 128,\n",
    "                        \"buffer_size\": 100000,\n",
    "                        \"learning_rate\": 0.00003,\n",
    "                        \"learning_starts\": 100,\n",
    "                        \"ent_coef\": \"auto_0.1\",\n",
    "                        \"device\": 'cuda',\n",
    "                        \"verbose\": 0,\n",
    "                        '_init_setup_model': True,\n",
    "                        'seed': 1024\n",
    "                        },\n",
    "                  \"ppo\": {\n",
    "                        'env': env,\n",
    "                        \"policy\":\"MlpPolicy\",    \n",
    "                        \"n_steps\": 2048,\n",
    "                        \"ent_coef\": 0.005,\n",
    "                        \"learning_rate\": 0.0001,\n",
    "                        \"batch_size\": 128,\n",
    "                        \"device\": 'cuda',\n",
    "                        \"verbose\": 0,\n",
    "                        '_init_setup_model': True,\n",
    "                        'seed': 1024\n",
    "                        }\n",
    "                 }\n",
    "        return PARAMS[Model]  \n",
    "    \n",
    "    StockEnv_params = {\n",
    "        'initial_account': initial_account,\n",
    "        'df': df,\n",
    "        'reward_low': reward_low,\n",
    "        'reward_high' : reward_high,\n",
    "        'reward_tipo' : reward_tipo   \n",
    "    }\n",
    "    print('\\nAprendizado modelo: ' + Model + \\\n",
    "          ' método de recompensa: ' + reward_tipo  + '_low_' + str(reward_low) \\\n",
    "          + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps))\n",
    "    # Create log dir\n",
    "    log_dir = \"/tmp/gym/\"\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    env1 = FinanceMultiStockEnv(**StockEnv_params)\n",
    "    # wrap environment\n",
    "    env = make_vec_env(lambda: env1, n_envs=1, monitor_dir=log_dir)\n",
    "    # Create Callback\n",
    "    callback = SimpleCallback()\n",
    "    LearnedModel = Models(Model)(**(Params(Model,env))).learn(total_timesteps=total_timesteps, callback=callback)\n",
    "    if verbose:\n",
    "        plt.figure(figsize=(20,10) ) \n",
    "        plt.title('Riqueza Acumulada')\n",
    "        plt.plot(grana)\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(20,10)) \n",
    "        plt.title('Posição Líquida Disponível')\n",
    "        plt.plot(caixa)\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(20,10) ) \n",
    "        plt.title('Posição Acionária')\n",
    "        plt.plot(shares)\n",
    "        plt.show()\n",
    "    # salva o modelo treinado\n",
    "    LearnedModel.save('./models/model_' + Model + '_' + reward_tipo + '_low_' + str(reward_low) \\\n",
    "                      + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictModel(Model, \n",
    "                 df ,\n",
    "                 initial_account = 1e6 ,\n",
    "                 reward_low = -1 ,  \n",
    "                 reward_high = 0.1 , \n",
    "                 reward_tipo = 'spot', # 'mfi' ou 'spot' ou 'rsi' \n",
    "                 total_timesteps = 10000,\n",
    "                 verbose = False): \n",
    "    global resultados\n",
    "    def Models(Model):\n",
    "        MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}\n",
    "        return MODELS[Model]\n",
    "    def DRL_prediction(model, environment):\n",
    "        test_env, test_obs = environment.get_sb_env()\n",
    "        for i in range(environment.ary.shape[0]):\n",
    "            action, _states = model.predict(test_obs)\n",
    "            test_obs, rewards, dones, info = test_env.step(action)\n",
    "            if dones[0]:\n",
    "                break\n",
    "        return\n",
    "    StockEnv_params = {\n",
    "        'initial_account': initial_account,\n",
    "        'df': df,\n",
    "        'reward_low': reward_low,\n",
    "        'reward_high' : reward_high,\n",
    "        'reward_tipo' : reward_tipo  \n",
    "    }\n",
    "    print('Predição modelo: ' + Model + ' método de recompensa: ' + reward_tipo + '_low_' + str(reward_low) \\\n",
    "          + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps))\n",
    "    # restaura o modelo treinado\n",
    "    PredictionModel = Models(Model).load('./models/model_' + Model + '_' + reward_tipo + '_low_' + str(reward_low) \\\n",
    "                                         + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps))\n",
    "    DRL_prediction(model = PredictionModel, environment=StockEnv(**StockEnv_params))\n",
    "    resultados['grana_' + Model + '_' + reward_tipo + '_low_' + str(reward_low) \\\n",
    "               + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps) ] = grana\n",
    "    resultados['caixa_' + Model + '_' + reward_tipo + '_low_' + str(reward_low) \\\n",
    "               + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps) ] = caixa\n",
    "    resultados['shares_' + Model + '_' + reward_tipo + '_low_' + str(reward_low) \\\n",
    "               + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps) ] = shares\n",
    "    if verbose:\n",
    "        y_list = pd.Series({'max grana': max(grana),'média grana': np.mean(grana),'min grana': min(grana),'última grana': grana[-1]} )\n",
    "        display(HTML(pd.DataFrame(y_list).transpose().to_html(index=False)))\n",
    "        y_list = resultados.loc[resultados.index[-1],['grana_' + Model + '_' + reward_tipo + \\\n",
    "                                                      '_low_' + str(reward_low) \\\n",
    "                                                      + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps),\n",
    "                                                      'BuyHold']].sort_values(ascending=False)\n",
    "        display(HTML(pd.DataFrame(y_list).transpose().to_html(index=False)))\n",
    "        resultados.plot(x='date', y = y_list.index, title = 'Riqueza Acumulada X Buy and Hold', \n",
    "                secondary_y=False,figsize=(20,8),grid=True).legend(loc='upper left')\n",
    "        plt.show()\n",
    "        resultados.plot(x='date', y=['caixa_' + Model + '_' + reward_tipo + \\\n",
    "                                                      '_low_' + str(reward_low) \\\n",
    "                                                      + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps)], \n",
    "                        title = 'Posição Líquida Disponível', \n",
    "                secondary_y=False,figsize=(20,8),grid=True).legend(loc='upper left')\n",
    "        plt.show()\n",
    "        resultados.plot(x='date', y=['shares_' + Model + '_' + reward_tipo + \\\n",
    "                                                      '_low_' + str(reward_low) \\\n",
    "                                                      + '_high_' + str(reward_high) + '_timesteps_' + str(total_timesteps)], \n",
    "                        title = 'Posição Acionária',  \n",
    "                secondary_y=False,figsize=(20,8),grid=True).legend(loc='upper left')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockEnv(gym.Env):  # custom env\n",
    "    \n",
    "\n",
    "    def __init__(self,\n",
    "                 df, \n",
    "                 initial_account=1e6, \n",
    "                 transaction_fee_percent=1e-3,\n",
    "                 reward_low = -5,\n",
    "                 reward_high = 10,\n",
    "                 reward_tipo = 'spot'  # 'mfi' ou 'spot' ou 'rsi'               \n",
    "                ):\n",
    "        \n",
    "        global atua, grana, caixa, shares\n",
    "        \n",
    "        atua = []\n",
    "        grana = []\n",
    "        caixa = []\n",
    "        shares = []\n",
    "        self.reward_low = copy(reward_low)\n",
    "        self.reward_high = copy(reward_high)\n",
    "        self.stock_dim = 1\n",
    "        self.reward_tipo = copy(reward_tipo)\n",
    "        self.initial_account = initial_account\n",
    "        self.transaction_fee_percent = transaction_fee_percent\n",
    "        # ary: (date, item*stock_dim), item: (adjcp, macd, rsi, cci, adx)\n",
    "        self.mfi_values = df.loc[:,['mfi']].values        \n",
    "        self.rsi_values = df.loc[:,['rsi']].values        \n",
    "        self.ary = df.loc[:,['close','rsi','mfi']].values\n",
    "        self.chama_reward = {'mfi':self._reward_mfi,\n",
    "                             'rsi':self._reward_rsi,\n",
    "                             'spot':self._reward_spot}\n",
    "        # reset\n",
    "        self.day = 0\n",
    "        self.initial_account__reset = self.initial_account\n",
    "        self.account = self.initial_account__reset\n",
    "        self.day_npy = self.ary[self.day]\n",
    "        self.stocks = 0.0\n",
    "        self.total_asset = self.account + (self.day_npy[0] * self.stocks)\n",
    "        self.episode_return = 0.0  # Compatibility for ElegantRL 2020-12-21\n",
    "        self.gamma_return = 0.0\n",
    "\n",
    "        '''env information'''\n",
    "        self.env_name = 'FinanceStock-v2'\n",
    "        self.state_dim = 1 + 30 + 1 # permite verificar 10 dias de pregões, atual + 9 anteriores\n",
    "        self.action_dim = self.stock_dim\n",
    "        self.if_discrete = False\n",
    "        self.max_step = self.ary.shape[0]\n",
    "        self.action_space = spaces.Box(low = -1, high = 1,shape = (self.stock_dim,)) \n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_dim,))\n",
    "        grana.append(self.total_asset)\n",
    "        caixa.append(self.account)\n",
    "        shares.append(self.stocks)\n",
    "        \n",
    "    def _reward_spot(self,action):\n",
    "        self._reward_spot =  (self.next_total_asset - self.total_asset) * 2 ** -16  # notice scaling!\n",
    "        return self._reward_spot\n",
    "\n",
    "    def _reward_rsi(self,action):  # considera rsi\n",
    "        # Wilder considered RSI overbought above 70 and oversold below 30\n",
    "        \n",
    "        if self.account <= 0: # não tem caixa\n",
    "            \n",
    "            if self.stocks <= 0: # não tem ações\n",
    "                \n",
    "                return self.reward_low # não tem caixa nem ações: ruína                \n",
    "                \n",
    "            else: # tem ações\n",
    "\n",
    "                if self.rsi_value [0] > 70: # mercado está sobre comprado\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_low # opção errada segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_high # opção certa vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.rsi_value [0] >= 30) and (self.rsi_value [0] <= 70): # mercado está normal\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.rsi_value [0] < 30) : # mercado está sobre vendido\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "        else: # tem caixa\n",
    "            \n",
    "            if self.stocks <= 0: # não tem ações\n",
    "\n",
    "                if self.rsi_value [0] > 70: # mercado está sobre comprado\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.rsi_value [0] >= 30) and (self.rsi_value [0] <= 70): # mercado está normal\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.rsi_value [0] < 30) : # mercado está sobre vendido\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_low # opção errada segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_high # opção correta comprar \n",
    "\n",
    "            else: # tem ações\n",
    "\n",
    "                if self.rsi_value [0] > 70: # mercado está sobre comprado\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_low # opção errada segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_high # opção correta vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.rsi_value [0] >= 30) and (self.rsi_value [0] <= 70): # mercado está normal\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.rsi_value [0] < 30) : # mercado está sobre vendido\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_low # opção errada segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_high # opção correta comprar \n",
    "    \n",
    "    def _reward_mfi(self, action ): # considera mfi\n",
    "        \n",
    "        if self.account <= 0: # não tem caixa\n",
    "            \n",
    "            if self.stocks <= 0: # não tem ações\n",
    "                \n",
    "                return self.reward_low # não tem caixa nem ações: ruína                \n",
    "                \n",
    "            else: # tem ações\n",
    "\n",
    "                if self.mfi_value [0] > 80: # mercado está sobre comprado\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_low # opção errada segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_high # opção certa vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.mfi_value [0] >= 20) and (self.mfi_value [0] <= 80): # mercado está normal\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.mfi_value [0] < 20) : # mercado está sobre vendido\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "        else: # tem caixa\n",
    "            \n",
    "            if self.stocks <= 0: # não tem ações\n",
    "\n",
    "                if self.mfi_value [0] > 80: # mercado está sobre comprado\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.mfi_value [0] >= 20) and (self.mfi_value [0] <= 80): # mercado está normal\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.mfi_value [0] < 20) : # mercado está sobre vendido\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_low # opção errada segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_high # opção correta comprar \n",
    "\n",
    "            else: # tem ações\n",
    "\n",
    "                if self.mfi_value [0] > 80: # mercado está sobre comprado\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_low # opção errada segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_high # opção correta vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.mfi_value [0] >= 20) and (self.mfi_value [0] <= 80): # mercado está normal\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_high # opção correta segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_low # opção errada comprar \n",
    "\n",
    "                if (self.mfi_value [0] < 20) : # mercado está sobre vendido\n",
    "\n",
    "                    if action[0] == 0:\n",
    "                        return self.reward_low # opção errada segurar (holding)\n",
    "                    if action[0] < 0:\n",
    "                        return self.reward_low # opção errada vender\n",
    "                    if action[0] >  0:\n",
    "                        return self.reward_high # opção correta comprar \n",
    "    \n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        self.episode_return = 0.0  # Compatibility for ElegantRL 2020-12-21\n",
    "        self.gamma_return = 0.0\n",
    "        self.initial_account__reset = self.initial_account  #* rd.uniform(0.9, 1.1)  # reset()\n",
    "        self.account = self.initial_account__reset\n",
    "        self.stocks = 0.0\n",
    "        # total_asset = account + (adjcp * stocks).sum()\n",
    "        self.total_asset = self.account + (self.day_npy * self.stocks)\n",
    "        self.day = 0\n",
    "        self.day_npy = self.ary[self.day]\n",
    "        self.total_asset = self.account + (self.day_npy[0] * self.stocks)\n",
    "        self.state = self._update_state()\n",
    "        self.day += 1\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        atua.append(action[0])\n",
    "        \"\"\"buy or sell stock\"\"\"\n",
    "        adj = self.day_npy[0]\n",
    "        self.mfi_value = self.mfi_values[self.day]\n",
    "        self.rsi_value = self.rsi_values[self.day]\n",
    "        if (action[0] > 0) and (self.account > 0):  # buy_stock\n",
    "            adj *= 1 + self.transaction_fee_percent # levar em conta o custo da compra\n",
    "            delta_stock = (self.account *  action[0]) // adj\n",
    "            self.account -= adj * delta_stock \n",
    "            self.stocks += delta_stock\n",
    "        elif (action[0] < 0) and (self.stocks > 0):  # sell_stock\n",
    "            delta_stock = int (self.stocks *  abs (action[0]))\n",
    "            self.account += adj * delta_stock * (1 - self.transaction_fee_percent) # levar em conta o custo da venda\n",
    "            self.stocks -= delta_stock\n",
    "        \"\"\"update day\"\"\"\n",
    "        self.day_npy = self.ary[self.day]\n",
    "        self.state = self._update_state()\n",
    "        self.day += 1\n",
    "        if self.day == self.max_step or ((self.account == 0) and (self.stocks == 0)):\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        self.next_total_asset = self.account + (self.day_npy[0] * self.stocks)\n",
    "        \n",
    "        self.reward = self.chama_reward[self.reward_tipo](action)\n",
    "\n",
    "        self.total_asset = self.next_total_asset\n",
    "        self.gamma_return = self.gamma_return * 0.99 + self.reward  # notice: gamma_r seems good? Yes\n",
    "        if done:\n",
    "            self.reward += self.gamma_return\n",
    "            self.gamma_return = 0.0  # env.reset()\n",
    "            self.episode_return = self.next_total_asset / self.initial_account  # cumulative_return_rate\n",
    "        grana.append(self.total_asset)\n",
    "        caixa.append(self.account)\n",
    "        shares.append(self.stocks)\n",
    "        return self.state, self.reward, done, {}\n",
    "    \n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs\n",
    "    \n",
    "    def _update_state(self):\n",
    "        state = np.hstack((self.account * 2 ** -16, \n",
    "                           self.ary[self.day] * 2 ** -8, \n",
    "                           self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8,\n",
    "                           self.ary[self.day-2] * 2 ** -8 if (self.day-2) >= 0 else \\\n",
    "                               (self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8),\n",
    "                           self.ary[self.day-3] * 2 ** -8 if (self.day-3) >= 0 else \\\n",
    "                               (self.ary[self.day-2] * 2 ** -8 if (self.day-2) >= 0 else \\\n",
    "                               (self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8)),\n",
    "                           self.ary[self.day-4] * 2 ** -8 if (self.day-4) >= 0 else \\\n",
    "                               (self.ary[self.day-3] * 2 ** -8 if (self.day-3) >= 0 else \\\n",
    "                               (self.ary[self.day-2] * 2 ** -8 if (self.day-2) >= 0 else \\\n",
    "                               (self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8))),\n",
    "                           self.ary[self.day-5] * 2 ** -8 if (self.day-5) >= 0 else \\\n",
    "                               (self.ary[self.day-4] * 2 ** -8 if (self.day-4) >= 0 else \\\n",
    "                               (self.ary[self.day-3] * 2 ** -8 if (self.day-3) >= 0 else \\\n",
    "                               (self.ary[self.day-2] * 2 ** -8 if (self.day-2) >= 0 else \\\n",
    "                               (self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8)))),\n",
    "                           self.ary[self.day-6] * 2 ** -8 if (self.day-6) >= 0 else \\\n",
    "                               (self.ary[self.day-5] * 2 ** -8 if (self.day-5) >= 0 else \\\n",
    "                               (self.ary[self.day-4] * 2 ** -8 if (self.day-4) >= 0 else \\\n",
    "                               (self.ary[self.day-3] * 2 ** -8 if (self.day-3) >= 0 else \\\n",
    "                               (self.ary[self.day-2] * 2 ** -8 if (self.day-2) >= 0 else \\\n",
    "                               (self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8))))),\n",
    "                           self.ary[self.day-7] * 2 ** -8 if (self.day-7) >= 0 else \\\n",
    "                               (self.ary[self.day-6] * 2 ** -8 if (self.day-6) >= 0 else \\\n",
    "                               (self.ary[self.day-5] * 2 ** -8 if (self.day-5) >= 0 else \\\n",
    "                               (self.ary[self.day-4] * 2 ** -8 if (self.day-4) >= 0 else \\\n",
    "                               (self.ary[self.day-3] * 2 ** -8 if (self.day-3) >= 0 else \\\n",
    "                               (self.ary[self.day-2] * 2 ** -8 if (self.day-2) >= 0 else \\\n",
    "                               (self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8)))))),\n",
    "                           self.ary[self.day-8] * 2 ** -8 if (self.day-8) >= 0 else \\\n",
    "                               (self.ary[self.day-7] * 2 ** -8 if (self.day-7) >= 0 else \\\n",
    "                               (self.ary[self.day-6] * 2 ** -8 if (self.day-6) >= 0 else \\\n",
    "                               (self.ary[self.day-5] * 2 ** -8 if (self.day-5) >= 0 else \\\n",
    "                               (self.ary[self.day-4] * 2 ** -8 if (self.day-4) >= 0 else \\\n",
    "                               (self.ary[self.day-3] * 2 ** -8 if (self.day-3) >= 0 else \\\n",
    "                               (self.ary[self.day-2] * 2 ** -8 if (self.day-2) >= 0 else \\\n",
    "                               (self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8))))))),\n",
    "                           self.ary[self.day-9] * 2 ** -8 if (self.day-9) >= 0 else \\\n",
    "                               (self.ary[self.day-8] * 2 ** -8 if (self.day-8) >= 0 else \\\n",
    "                               (self.ary[self.day-7] * 2 ** -8 if (self.day-7) >= 0 else \\\n",
    "                               (self.ary[self.day-6] * 2 ** -8 if (self.day-6) >= 0 else \\\n",
    "                               (self.ary[self.day-5] * 2 ** -8 if (self.day-5) >= 0 else \\\n",
    "                               (self.ary[self.day-4] * 2 ** -8 if (self.day-4) >= 0 else \\\n",
    "                               (self.ary[self.day-3] * 2 ** -8 if (self.day-3) >= 0 else \\\n",
    "                               (self.ary[self.day-2] * 2 ** -8 if (self.day-2) >= 0 else \\\n",
    "                               (self.ary[self.day-1] * 2 ** -8 if (self.day-1) >= 0 else self.ary[self.day] * 2 ** -8)))))))),\n",
    "                           self.stocks * 2 ** -12,), \n",
    "                         ).astype(np.float32)\n",
    "        return state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "atua = []\n",
    "grana = []\n",
    "caixa = []\n",
    "shares = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#tickers = [\"ABEV3.SA\", \"ITSA4.SA\", \"WEGE3.SA\", \"USIM5.SA\", \"VALE3.SA\", '^BVSP']\n",
    "# S&P 500: '^GSPC'\n",
    "# Dow Jones Index: '^DJI'\n",
    "# NASDAQ 100: '^NDX'\n",
    "# Apple: 'AAPL'\n",
    "# leitura dos dados\n",
    "tic = 'AAPL'\n",
    "data_df = yf.download(tic, start='2009-01-01', end='2021-03-01')\n",
    "data_df = ta.utils.dropna(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_ratio = data_df['Adj Close'] / data_df['Close']\n",
    "data_df['Open'] = data_df['Open'] * adjust_ratio\n",
    "data_df['High'] = data_df['High'] * adjust_ratio\n",
    "data_df['Low'] = data_df['Low'] * adjust_ratio\n",
    "data_df['Close'] = data_df['Close'] * adjust_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index, we want to use numbers as index instead of dates\n",
    "data_df = data_df.reset_index()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the column names to standardized names\n",
    "data_df.columns = [\n",
    "    \"date\",\n",
    "    \"open\",\n",
    "    \"high\",\n",
    "    \"low\",\n",
    "    \"close\",\n",
    "    \"adjcp\",\n",
    "    \"volume\",\n",
    "#     \"tic\",\n",
    "]\n",
    "ajuste_close = data_df[\"adjcp\"] / data_df[\"close\"]\n",
    "data_df[\"open\"] = data_df[\"open\"] * ajuste_close\n",
    "data_df[\"high\"] = data_df[\"high\"] * ajuste_close\n",
    "data_df[\"low\"] = data_df[\"low\"] * ajuste_close\n",
    "data_df[\"close\"] = data_df[\"close\"] * ajuste_close\n",
    "# drop the adjusted close price column\n",
    "data_df.drop([\"adjcp\"], axis ='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'low', 'close', 'volume'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of DataFrame:  (3059, 6)\n"
     ]
    }
   ],
   "source": [
    "# corrige formato da data\n",
    "data_df['date'] = pd.to_datetime(data_df['date'], errors='coerce')\n",
    "# create day of the week column (monday = 0)\n",
    "# data_df['day'] = data_df['date'].dt.dayofweek       \n",
    "# convert date to standard string format, easy to filter\n",
    "data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "# drop missing data\n",
    "data_df = data_df.dropna()\n",
    "data_df = data_df.reset_index(drop=True)\n",
    "print(\"Shape of DataFrame: \", data_df.shape)\n",
    "data_df = data_df.sort_values(by=['date'\n",
    "#                                   ,'tic'\n",
    "                                 ]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>2.641925</td>\n",
       "      <td>2.800662</td>\n",
       "      <td>2.619776</td>\n",
       "      <td>2.791740</td>\n",
       "      <td>746015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>2.866187</td>\n",
       "      <td>2.958783</td>\n",
       "      <td>2.852036</td>\n",
       "      <td>2.909563</td>\n",
       "      <td>1181608400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>2.951709</td>\n",
       "      <td>2.989239</td>\n",
       "      <td>2.842192</td>\n",
       "      <td>2.861573</td>\n",
       "      <td>1289310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-07</td>\n",
       "      <td>2.824350</td>\n",
       "      <td>2.845576</td>\n",
       "      <td>2.776667</td>\n",
       "      <td>2.799739</td>\n",
       "      <td>753048800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-08</td>\n",
       "      <td>2.781897</td>\n",
       "      <td>2.865572</td>\n",
       "      <td>2.769899</td>\n",
       "      <td>2.851728</td>\n",
       "      <td>673500800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-01-09</td>\n",
       "      <td>2.867418</td>\n",
       "      <td>2.872647</td>\n",
       "      <td>2.772976</td>\n",
       "      <td>2.786511</td>\n",
       "      <td>546845600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>2.782819</td>\n",
       "      <td>2.799124</td>\n",
       "      <td>2.693299</td>\n",
       "      <td>2.727447</td>\n",
       "      <td>617716400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>2.714526</td>\n",
       "      <td>2.760670</td>\n",
       "      <td>2.656384</td>\n",
       "      <td>2.698221</td>\n",
       "      <td>798397600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-01-14</td>\n",
       "      <td>2.653000</td>\n",
       "      <td>2.684070</td>\n",
       "      <td>2.606240</td>\n",
       "      <td>2.625005</td>\n",
       "      <td>1021664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-01-15</td>\n",
       "      <td>2.478574</td>\n",
       "      <td>2.587782</td>\n",
       "      <td>2.462577</td>\n",
       "      <td>2.565017</td>\n",
       "      <td>1831634000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>134.350006</td>\n",
       "      <td>135.529999</td>\n",
       "      <td>133.690002</td>\n",
       "      <td>135.369995</td>\n",
       "      <td>60029300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>135.490005</td>\n",
       "      <td>136.009995</td>\n",
       "      <td>132.789993</td>\n",
       "      <td>133.190002</td>\n",
       "      <td>80576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>131.250000</td>\n",
       "      <td>132.220001</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>130.839996</td>\n",
       "      <td>97918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>129.199997</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>127.410004</td>\n",
       "      <td>129.710007</td>\n",
       "      <td>96856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>130.240005</td>\n",
       "      <td>130.710007</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>129.869995</td>\n",
       "      <td>87668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>128.009995</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>125.599998</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>103916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>123.760002</td>\n",
       "      <td>126.709999</td>\n",
       "      <td>118.389999</td>\n",
       "      <td>125.860001</td>\n",
       "      <td>158273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>124.940002</td>\n",
       "      <td>125.559998</td>\n",
       "      <td>122.230003</td>\n",
       "      <td>125.349998</td>\n",
       "      <td>111039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>124.680000</td>\n",
       "      <td>126.459999</td>\n",
       "      <td>120.540001</td>\n",
       "      <td>120.989998</td>\n",
       "      <td>148199500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>122.589996</td>\n",
       "      <td>124.849998</td>\n",
       "      <td>121.199997</td>\n",
       "      <td>121.260002</td>\n",
       "      <td>164320000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(data_df.head(10).to_html(index=True)))\n",
    "display(HTML(data_df.tail(10).to_html(index=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Strength Index (RSI)\n",
    "# Compares the magnitude of recent gains and losses over a specified time period to measure speed and change of price movements of a security. \n",
    "# It is primarily used to attempt to identify overbought or oversold conditions in the trading of an asset.\n",
    "\n",
    "# Add SRI features\n",
    "data_df['rsi'] = RSIIndicator(close=data_df[\"close\"], window=14).rsi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Money Flow Index (MFI) Indicator\n",
    "# The Money Flow Index (MFI) is an oscillator that uses both price and volume to measure buying and selling pressure. \n",
    "# Created by Gene Quong and Avrum Soudack, MFI is also known as volume-weighted RSI. \n",
    "# MFI starts with the typical price for each period. \n",
    "# Money flow is positive when the typical price rises (buying pressure) and negative when the typical price declines (selling pressure). \n",
    "# A ratio of positive and negative money flow is then plugged into an RSI formula to create an oscillator that moves between zero \n",
    "# and one hundred. \n",
    "# As a momentum oscillator tied to volume, MFI is best suited to identify reversals and price extremes with a variety of signals.\n",
    "# Add Money Flow Index (MFI)  features\n",
    "data_df['mfi'] = MFIIndicator(high = data_df[\"high\"], low = data_df[\"low\"],close=data_df[\"close\"],\n",
    "                              volume = data_df[\"volume\"], window=14).money_flow_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'open', 'high', 'low', 'close', 'volume', 'rsi', 'mfi'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.fillna(method=\"bfill\").fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>mfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>2.641925</td>\n",
       "      <td>2.800662</td>\n",
       "      <td>2.619776</td>\n",
       "      <td>2.791740</td>\n",
       "      <td>746015200</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>2.866187</td>\n",
       "      <td>2.958783</td>\n",
       "      <td>2.852036</td>\n",
       "      <td>2.909563</td>\n",
       "      <td>1181608400</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>2.951709</td>\n",
       "      <td>2.989239</td>\n",
       "      <td>2.842192</td>\n",
       "      <td>2.861573</td>\n",
       "      <td>1289310400</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-07</td>\n",
       "      <td>2.824350</td>\n",
       "      <td>2.845576</td>\n",
       "      <td>2.776667</td>\n",
       "      <td>2.799739</td>\n",
       "      <td>753048800</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-08</td>\n",
       "      <td>2.781897</td>\n",
       "      <td>2.865572</td>\n",
       "      <td>2.769899</td>\n",
       "      <td>2.851728</td>\n",
       "      <td>673500800</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2009-01-09</td>\n",
       "      <td>2.867418</td>\n",
       "      <td>2.872647</td>\n",
       "      <td>2.772976</td>\n",
       "      <td>2.786511</td>\n",
       "      <td>546845600</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2009-01-12</td>\n",
       "      <td>2.782819</td>\n",
       "      <td>2.799124</td>\n",
       "      <td>2.693299</td>\n",
       "      <td>2.727447</td>\n",
       "      <td>617716400</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2009-01-13</td>\n",
       "      <td>2.714526</td>\n",
       "      <td>2.760670</td>\n",
       "      <td>2.656384</td>\n",
       "      <td>2.698221</td>\n",
       "      <td>798397600</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-01-14</td>\n",
       "      <td>2.653000</td>\n",
       "      <td>2.684070</td>\n",
       "      <td>2.606240</td>\n",
       "      <td>2.625005</td>\n",
       "      <td>1021664000</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2009-01-15</td>\n",
       "      <td>2.478574</td>\n",
       "      <td>2.587782</td>\n",
       "      <td>2.462577</td>\n",
       "      <td>2.565017</td>\n",
       "      <td>1831634000</td>\n",
       "      <td>50.419083</td>\n",
       "      <td>33.618418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>rsi</th>\n",
       "      <th>mfi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>134.350006</td>\n",
       "      <td>135.529999</td>\n",
       "      <td>133.690002</td>\n",
       "      <td>135.369995</td>\n",
       "      <td>60029300</td>\n",
       "      <td>52.969979</td>\n",
       "      <td>39.103818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>2021-02-16</td>\n",
       "      <td>135.490005</td>\n",
       "      <td>136.009995</td>\n",
       "      <td>132.789993</td>\n",
       "      <td>133.190002</td>\n",
       "      <td>80576300</td>\n",
       "      <td>48.180033</td>\n",
       "      <td>32.015357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>131.250000</td>\n",
       "      <td>132.220001</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>130.839996</td>\n",
       "      <td>97918500</td>\n",
       "      <td>43.602697</td>\n",
       "      <td>33.346601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>129.199997</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>127.410004</td>\n",
       "      <td>129.710007</td>\n",
       "      <td>96856700</td>\n",
       "      <td>41.558172</td>\n",
       "      <td>34.802668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>130.240005</td>\n",
       "      <td>130.710007</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>129.869995</td>\n",
       "      <td>87668800</td>\n",
       "      <td>41.973038</td>\n",
       "      <td>44.960882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>2021-02-22</td>\n",
       "      <td>128.009995</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>125.599998</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>103916400</td>\n",
       "      <td>35.422594</td>\n",
       "      <td>35.966547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>123.760002</td>\n",
       "      <td>126.709999</td>\n",
       "      <td>118.389999</td>\n",
       "      <td>125.860001</td>\n",
       "      <td>158273000</td>\n",
       "      <td>35.208528</td>\n",
       "      <td>27.117843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>124.940002</td>\n",
       "      <td>125.559998</td>\n",
       "      <td>122.230003</td>\n",
       "      <td>125.349998</td>\n",
       "      <td>111039900</td>\n",
       "      <td>34.393128</td>\n",
       "      <td>35.313688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>124.680000</td>\n",
       "      <td>126.459999</td>\n",
       "      <td>120.540001</td>\n",
       "      <td>120.989998</td>\n",
       "      <td>148199500</td>\n",
       "      <td>28.348703</td>\n",
       "      <td>27.146280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>2021-02-26</td>\n",
       "      <td>122.589996</td>\n",
       "      <td>124.849998</td>\n",
       "      <td>121.199997</td>\n",
       "      <td>121.260002</td>\n",
       "      <td>164320000</td>\n",
       "      <td>29.178774</td>\n",
       "      <td>19.903630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(data_df.head(10).to_html(index=True)))\n",
    "display(HTML(data_df.tail(10).to_html(index=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = data_split(data_df, start = config.START_DATE, end = config.START_TRADE_DATE)\n",
    "#trade = data_split(data_df, start = config.START_TRADE_DATE, end = config.END_DATE)\n",
    "train = data_split(data_df, start = '2009-01-01', end = '2019-01-01')\n",
    "trade = data_split(data_df, start = '2019-01-01', end = '2021-03-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.plot(x=\"date\", y=[\"close\"], \n",
    "        secondary_y=False,figsize=(20,8),grid=True).legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trade.plot(x=\"date\", y=[\"close\"], \n",
    "        secondary_y=False,figsize=(20,8),grid=True).legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "JY5wTwYjGTrg"
   },
   "outputs": [],
   "source": [
    "StockEnv_params = {\n",
    "    'initial_account': 1000000,\n",
    "    'df': train,\n",
    "    'reward_low': 0.1,\n",
    "    'reward_high' : 0.4,\n",
    "    'reward_tipo' : 'spot' # 'mfi' ou 'spot'\n",
    "}\n",
    "# Instantiate the env\n",
    "env1 = StockEnv(**StockEnv_params)\n",
    "# If the environment don't follow the interface, an error will be thrown\n",
    "check_env(env1, warn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./models\"):\n",
    "    os.makedirs(\"./models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### Aprendizado de todos os Modelos X Todos os tipos de recompensa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10060\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10000\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Num timesteps: 10240\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40240\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40000\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Num timesteps: 40960\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 80480\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 80000\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Num timesteps: 81920\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: a2c método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: ddpg método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: td3 método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100600\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: sac método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100000\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Num timesteps: 100352\n",
      "Aprendizado modelo: ppo método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Num timesteps: 100352"
     ]
    }
   ],
   "source": [
    "for steps in [10000,40000,80000,100000]:\n",
    "    for modelo in ['a2c', 'ddpg', 'td3', 'sac', 'ppo']:\n",
    "        for recompensa in ['mfi','spot','rsi' ]:\n",
    "            for reward_high in [0.1,0.25,0.5,0.75,1]:\n",
    "                for reward_low in [-0.1,-0.25,-0.5,-0.75,-1]:\n",
    "                    LearnModel(modelo,  # 'a2c', 'ddpg', 'td3', 'sac', 'ppo'\n",
    "                               df = train ,\n",
    "                               reward_low = reward_low ,\n",
    "                               reward_high = reward_high , \n",
    "                               reward_tipo = recompensa, # 'mfi' ou 'spot' ou 'rsi' \n",
    "                               total_timesteps = steps) \n",
    "                    if recompensa == 'spot': # para recompensa spot não há necessidade de variar os valores low e high\n",
    "                        break\n",
    "                if recompensa == 'spot': # para recompensa spot não há necessidade de variar os valores low e high\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### Predição de todos os Modelos X Todos os tipos de recompensa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da estratégia de buy and hold\n",
    "resultados = pd.DataFrame()\n",
    "resultados['date'] = trade ['date']\n",
    "qtde = 1e6 // (trade.loc[1,'close']*(1+1e-3)) # acrescenta os custos de compra\n",
    "resultados['BuyHold'] = trade ['close']*qtde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: spot_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.25_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.5_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.75_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_1_timesteps_10000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_1_timesteps_10000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: spot_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.25_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.5_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.75_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_1_timesteps_40000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_1_timesteps_40000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: spot_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.25_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.5_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.75_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_1_timesteps_80000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_1_timesteps_80000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: a2c método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: ddpg método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: td3 método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: sac método de recompensa: rsi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: mfi_low_-1_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: spot_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.25_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.5_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_0.75_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.1_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.25_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.5_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-0.75_high_1_timesteps_100000\n",
      "Predição modelo: ppo método de recompensa: rsi_low_-1_high_1_timesteps_100000\n"
     ]
    }
   ],
   "source": [
    "for steps in [10000,40000,80000,100000]:\n",
    "    for modelo in ['a2c', 'ddpg', 'td3', 'sac', 'ppo']:\n",
    "        for recompensa in ['mfi','spot','rsi' ]:\n",
    "            for reward_high in [0.1,0.25,0.5,0.75,1]:\n",
    "                for reward_low in [-0.1,-0.25,-0.5,-0.75,-1]:\n",
    "                    PredictModel(modelo, # 'a2c', 'ddpg', 'td3', 'sac', 'ppo'\n",
    "                                 df = trade ,\n",
    "                                 initial_account = 1e6 ,\n",
    "                                 reward_low = reward_low ,  \n",
    "                                 reward_high = reward_high , \n",
    "                                 reward_tipo = recompensa, # 'mfi' ou 'spot' ou 'rsi' \n",
    "                                 total_timesteps = steps) \n",
    "                    if recompensa == 'spot': # para recompensa spot não há necessidade de variar os valores low e high\n",
    "                        break\n",
    "                if recompensa == 'spot': # para recompensa spot não há necessidade de variar os valores low e high\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./resultados\"):\n",
    "    os.makedirs(\"./resultados\")\n",
    "resultados.to_pickle('./resultados/resultados.pkl') # salva o data frame resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
